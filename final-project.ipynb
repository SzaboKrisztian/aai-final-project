{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bd4fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import joblib\n",
    "from utils import render_single, render_multiple, get_dataset_files, extract_random_entries, generate_pixel_columns\n",
    "from IPython.display import display, Image as IPImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c021e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000000 entries from ['../dataset/garden.ndjson', '../dataset/trumpet.ndjson', '../dataset/dresser.ndjson', '../dataset/car.ndjson', '../dataset/hammer.ndjson', '../dataset/skyscraper.ndjson', '../dataset/sink.ndjson', '../dataset/umbrella.ndjson', '../dataset/calendar.ndjson', '../dataset/ambulance.ndjson', '../dataset/zigzag.ndjson', '../dataset/flower.ndjson', '../dataset/smiley face.ndjson', '../dataset/skateboard.ndjson', '../dataset/bat.ndjson', '../dataset/owl.ndjson', '../dataset/tooth.ndjson', '../dataset/animal migration.ndjson', '../dataset/dresser.ndjson', '../dataset/sailboat.ndjson', '../dataset/guitar.ndjson', '../dataset/microwave.ndjson', '../dataset/lighter.ndjson', '../dataset/fireplace.ndjson', '../dataset/pineapple.ndjson', '../dataset/aircraft carrier.ndjson', '../dataset/house.ndjson', '../dataset/tennis racquet.ndjson', '../dataset/snorkel.ndjson', '../dataset/umbrella.ndjson', '../dataset/blackberry.ndjson', '../dataset/mailbox.ndjson', '../dataset/pants.ndjson', '../dataset/snail.ndjson', '../dataset/key.ndjson', '../dataset/peas.ndjson', '../dataset/blackberry.ndjson', '../dataset/bee.ndjson', '../dataset/flower.ndjson', '../dataset/speedboat.ndjson', '../dataset/smiley face.ndjson', '../dataset/hand.ndjson', '../dataset/peanut.ndjson', '../dataset/string bean.ndjson', '../dataset/ant.ndjson', '../dataset/squirrel.ndjson', '../dataset/ice cream.ndjson', '../dataset/lobster.ndjson', '../dataset/wristwatch.ndjson', '../dataset/dog.ndjson', '../dataset/snowflake.ndjson', '../dataset/calendar.ndjson', '../dataset/bathtub.ndjson', '../dataset/hot tub.ndjson', '../dataset/sandwich.ndjson', '../dataset/tennis racquet.ndjson', '../dataset/sleeping bag.ndjson', '../dataset/bus.ndjson', '../dataset/bulldozer.ndjson', '../dataset/toilet.ndjson', '../dataset/ambulance.ndjson', '../dataset/see saw.ndjson', '../dataset/shorts.ndjson', '../dataset/streetlight.ndjson', '../dataset/car.ndjson', '../dataset/watermelon.ndjson', '../dataset/ladder.ndjson', '../dataset/pear.ndjson', '../dataset/toothpaste.ndjson', '../dataset/tree.ndjson', '../dataset/school bus.ndjson', '../dataset/hedgehog.ndjson', '../dataset/clock.ndjson', '../dataset/baseball bat.ndjson', '../dataset/cookie.ndjson', '../dataset/toothbrush.ndjson', '../dataset/knee.ndjson', '../dataset/snail.ndjson', '../dataset/diamond.ndjson', '../dataset/bottlecap.ndjson', '../dataset/bowtie.ndjson', '../dataset/campfire.ndjson', '../dataset/rain.ndjson', '../dataset/string bean.ndjson', '../dataset/bridge.ndjson', '../dataset/lollipop.ndjson', '../dataset/barn.ndjson', '../dataset/tree.ndjson', '../dataset/passport.ndjson', '../dataset/crown.ndjson', '../dataset/watermelon.ndjson', '../dataset/oven.ndjson', '../dataset/bird.ndjson', '../dataset/bicycle.ndjson', '../dataset/tooth.ndjson', '../dataset/dishwasher.ndjson', '../dataset/bandage.ndjson', '../dataset/television.ndjson', '../dataset/bee.ndjson', '../dataset/beard.ndjson']\n"
     ]
    }
   ],
   "source": [
    "files = get_dataset_files()\n",
    "files = random.choices(files, k=100)\n",
    "# files = ['../dataset/bat.ndjson', '../dataset/snowman.ndjson', '../dataset/spider.ndjson', '../dataset/tshirt.ndjson', '../dataset/binoculars.ndjson', '../dataset/eyeglasses.ndjson', '../dataset/cow.ndjson', '../dataset/dog.ndjson', '../dataset/guitar.ndjson', '../dataset/house.ndjson']\n",
    "data = [extract_random_entries(file, 10000, recognized=True) for file in files]\n",
    "flat_data = [item for sublist in data for item in sublist]\n",
    "df = pd.DataFrame.from_dict(flat_data, orient='columns')\n",
    "print(f'Loaded {len(df)} entries from {files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bdfd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = random.choice(flat_data)\n",
    "display(IPImage(render_single(img['drawing'])))\n",
    "print(img['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58443c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1000\n",
    "word = random.choice(df['word'].values)\n",
    "imgs = df[df['word'] == word].sample(count)\n",
    "display(IPImage(render_multiple(imgs['drawing'])))\n",
    "print(f'{count} superimposed {word}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4dd1514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving dataset to disk\n",
      "Train: 800000 entries, test: 200000 entries.\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(len(df))\n",
    "print('Done shuffling dataset')\n",
    "df = generate_pixel_columns(df, resolution=28, invert_color=True)\n",
    "print('Done generating pixel columns')\n",
    "df = df.reset_index()\n",
    "stamp = str(int(time.time()))\n",
    "pd.DataFrame.to_feather(df, '../data' + stamp)\n",
    "print('Done saving dataset to disk')\n",
    "train_amt = int(len(df) * .80)\n",
    "\n",
    "train = df[:train_amt]\n",
    "test = df[train_amt:]\n",
    "del df\n",
    "\n",
    "train = train.reset_index()\n",
    "test = test.reset_index()\n",
    "\n",
    "print(f'Train: {len(train)} entries, test: {len(test)} entries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4275f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "y = train['word']\n",
    "X = train.drop(columns=['countrycode', 'timestamp', 'recognized', 'key_id', 'drawing', 'word'])\n",
    "\n",
    "pca = PCA(.85)\n",
    "pca.fit(X)\n",
    "\n",
    "X = pca.transform(X)\n",
    "print(f'Keeping {pca.n_components_} features')\n",
    "\n",
    "#classifier = LinearSVC(random_state=0, max_iter=100000, dual=False)\n",
    "classifier = NuSVC(nu=.01)\n",
    "model = OneVsRestClassifier(classifier, n_jobs=-1).fit(X, y)\n",
    "joblib.dump(model, '../model' + stamp)\n",
    "joblib.dump(pca, '../pca' + stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test.sample(1)\n",
    "sample_predict = sample.drop(columns=['countrycode', 'timestamp', 'recognized', 'key_id', 'drawing', 'word'])\n",
    "\n",
    "sample_predict = pca.transform(sample_predict)\n",
    "\n",
    "prediction = model.predict(sample_predict)\n",
    "display(IPImage(render_single(sample['drawing'].iloc[0])))\n",
    "print(prediction[0])\n",
    "print(f\"{sample['word'].iloc[0]} == {prediction[0]} ? {sample['word'].iloc[0] == prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pca.transform(test.drop(columns=['countrycode', 'timestamp', 'recognized', 'key_id', 'drawing', 'word']))\n",
    "prediction = model.predict(test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_score = accuracy_score(test['word'].values.tolist(), prediction)\n",
    "print(f\"Accuracy score: {acc_score}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
