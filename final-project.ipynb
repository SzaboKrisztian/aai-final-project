{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb5155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import joblib\n",
    "import os\n",
    "from utils import render_single, render_multiple, get_dataset_files, extract_random_entries, extract_first_entries, generate_pixel_columns, load_run, extract_best_entries, equalize_by\n",
    "from IPython.display import display, Image as IPImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8cfca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 147342 entries from ['./dataset/power outlet.ndjson']\n",
      "Kept 18000 entries\n",
      "Done shuffling dataset\n",
      "Done generating pixel columns\n"
     ]
    }
   ],
   "source": [
    "load_existing_run = None\n",
    "\n",
    "if load_existing_run is None:\n",
    "    num_cats = 10\n",
    "    entries_per_cat = 5000\n",
    "    image_gen_params = {\n",
    "        'magnification': 1,\n",
    "        'resolution': 32,\n",
    "        'invert_color': True,\n",
    "        'stroke_width_scale': 1\n",
    "    }\n",
    "    \n",
    "    # files = get_dataset_files()\n",
    "    # files = random.sample(files, num_cats)\n",
    "    names = ['power outlet']\n",
    "    # names = ['ambulance','bed','bench','bread','castle','cell phone','chair','church','coffee cup','crown','cruise ship','cup','dishwasher','dresser','eye','face',\n",
    "        # 'fan','fire hydrant','fish','hammer','hat','helicopter','ice cream','lantern','passport','pickup truck','pillow','power outlet','sailboat','sandwich','snowman','star',\n",
    "        # 'strawberry','suitcase','table','telephone','traffic light','watermelon','wine glass']\n",
    "    files = list(map(lambda n: f\"./dataset/{n}.ndjson\", names))\n",
    "    df = extract_best_entries(files, recognized=True, skip_first=200)\n",
    "    \n",
    "    print(f'Loaded {len(df)} entries from {files}')\n",
    "    df = equalize_by(df, 'countrycode')\n",
    "    print(f'Kept {len(df)} entries')\n",
    "    df = df.sample(len(df))\n",
    "    print('Done shuffling dataset')\n",
    "    df = generate_pixel_columns(df, **image_gen_params).reset_index(drop=True)\n",
    "    print('Done generating pixel columns')\n",
    "\n",
    "else:\n",
    "    run = load_run(load_existing_run)\n",
    "    df = run['data']\n",
    "    num_cats = len(df['word'].value_counts())\n",
    "    entries_per_cat = df['word'].value_counts()[df['word'].value_counts().keys()[0]]\n",
    "    image_gen_params = run['img_params']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89adf31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = df.sample().iloc[0]\n",
    "display(IPImage(render_single(img['drawing'])))\n",
    "print(img['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1000 if entries_per_cat > 1000 else entries_per_cat\n",
    "word = random.choice(df['word'].values)\n",
    "imgs = df[df['word'] == word].sample(count)\n",
    "display(IPImage(render_multiple(imgs['drawing'])))\n",
    "print(f'{count} superimposed {word}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5623224f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 16200 entries, test: 1800 entries.\n"
     ]
    }
   ],
   "source": [
    "train_amt = int(len(df) * .9)\n",
    "\n",
    "train = df[:train_amt]\n",
    "test = df[train_amt:]\n",
    "# del df\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "print(f'Train: {len(train)} entries, test: {len(test)} entries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2dd0aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done generating features and target\n",
      "PCA & standardization done. Keeping 421 features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pca_on = True\n",
    "\n",
    "y = train['countrycode'].to_numpy()\n",
    "X = train.filter(regex='pixel.+').to_numpy()\n",
    "print(\"Done generating features and target\")\n",
    "\n",
    "if pca_on:\n",
    "    if load_existing_run is None:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        pca = PCA(.85)\n",
    "        X = pca.fit_transform(X)\n",
    "        print(f'PCA & standardization done. Keeping {pca.n_components_} features')\n",
    "    else:\n",
    "        scaler = run['scaler']\n",
    "        pca = run['pca']\n",
    "        X = scaler.transform(X)\n",
    "        X = pca.transform(X)\n",
    "        print('Applied scaler and PCA.')\n",
    "\n",
    "save_to_disk = False\n",
    "\n",
    "if save_to_disk:\n",
    "    stamp = str(int(time.time()))\n",
    "    folder = f'./runs/{stamp}/'\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    pd.DataFrame.to_feather(df, folder + 'data')\n",
    "    with open(folder + 'img_params', 'w') as f:\n",
    "        f.writelines(str(image_gen_params))\n",
    "    print('Done saving dataset to disk')\n",
    "    if pca_on:\n",
    "        joblib.dump(pca, folder + 'pca')\n",
    "        joblib.dump(scaler, folder + 'scaler')\n",
    "        print('Done saving PCA and scaler to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20703abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training MLPClassifier model in 349.35s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from itertools import repeat\n",
    "\n",
    "# Which class does this instance belong to?\n",
    "# in a multiclass classification problem can be reduced to:\n",
    "#  for each class in classes:\n",
    "#    does this instance belong to class? -> probability\n",
    "#  return the class with the highest probability\n",
    "\n",
    "classifiers = {\n",
    "    # 'LinearSVC': LinearSVC(dual=False),\n",
    "    # 'NuSVC': NuSVC(nu=.01),\n",
    "    # 'SGDClassifier': SGDClassifier(loss='epsilon_insensitive', penalty='elasticnet', n_jobs=-1),\n",
    "    # 'SVC': SVC(kernel='rbf', C=2.5, gamma=.0001105),\n",
    "    # 'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis(store_covariance=True),\n",
    "    # 'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis(store_covariance=True),\n",
    "    'MLPClassifier': MLPClassifier(hidden_layer_sizes=tuple(repeat(int(pca.n_components_ * 1.2), 3)), solver='lbfgs', alpha=1e-07),\n",
    "    # 'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    # 'ExtraTreeClassifier': ExtraTreeClassifier(),\n",
    "    # 'KernelRidge': KernelRidge(),\n",
    "    # 'GaussianProcess': GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "}\n",
    "\n",
    "models = {}\n",
    "start = time.time()\n",
    "for type, classifier in classifiers.items():\n",
    "    models[type] = OneVsRestClassifier(classifier, n_jobs=-1).fit(X, y)\n",
    "    end = time.time()\n",
    "    print(f\"Done training {type} model in {'{:.2f}'.format(end - start)}s\")\n",
    "    start = end\n",
    "\n",
    "if save_to_disk:\n",
    "    joblib.dump(models, folder + 'models')\n",
    "    print(\"Done saving models to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd12afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE: 0.008333333333333333\n",
      "SA: 0.007222222222222222\n",
      "FR: 0.006666666666666667\n",
      "CZ: 0.005555555555555556\n",
      "SE: 0.007222222222222222\n",
      "HU: 0.006666666666666667\n",
      "NL: 0.0044444444444444444\n",
      "CA: 0.007222222222222222\n",
      "KR: 0.007222222222222222\n",
      "RU: 0.01\n",
      "FI: 0.0022222222222222222\n",
      "PL: 0.0033333333333333335\n",
      "BR: 0.0044444444444444444\n",
      "US: 0.007222222222222222\n",
      "PH: 0.005555555555555556\n",
      "AU: 0.01\n",
      "GB: 0.008333333333333333\n",
      "IT: 0.0038888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AU       0.20      0.20      0.20        89\n",
      "          BR       0.08      0.08      0.08        97\n",
      "          CA       0.15      0.13      0.14       103\n",
      "          CZ       0.09      0.10      0.09       105\n",
      "          DE       0.12      0.14      0.13       111\n",
      "          FI       0.04      0.04      0.04       100\n",
      "          FR       0.11      0.11      0.11       109\n",
      "          GB       0.17      0.17      0.17        86\n",
      "          HU       0.12      0.12      0.12       104\n",
      "          IT       0.08      0.08      0.08        85\n",
      "          KR       0.12      0.13      0.12       102\n",
      "          NL       0.12      0.08      0.09       104\n",
      "          PH       0.10      0.11      0.10        95\n",
      "          PL       0.06      0.06      0.06        99\n",
      "          RU       0.13      0.18      0.15       101\n",
      "          SA       0.17      0.12      0.14       110\n",
      "          SE       0.12      0.12      0.12       105\n",
      "          US       0.11      0.14      0.12        95\n",
      "\n",
      "    accuracy                           0.12      1800\n",
      "   macro avg       0.12      0.12      0.12      1800\n",
      "weighted avg       0.12      0.12      0.11      1800\n",
      "\n",
      "0.11555555555555555\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, multilabel_confusion_matrix\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "cls_type, model = random.choice(list(models.items()))\n",
    "\n",
    "test_data = test.filter(regex='pixel.+').to_numpy()\n",
    "test_data = pca.transform(scaler.transform(test_data))\n",
    "\n",
    "countries = test['countrycode'].value_counts().keys()\n",
    "predictions = model.predict(test_data)\n",
    "truth = test['countrycode'].to_numpy()\n",
    "\n",
    "conf_matrix = {}\n",
    "for index in range(len(predictions)):\n",
    "    pred = predictions[index]\n",
    "    act = truth[index]\n",
    "    score = conf_matrix.get((pred, act), 0)\n",
    "    conf_matrix[(pred, act)] = score + 1\n",
    "\n",
    "# print('    ' + '  '.join(countries))\n",
    "# for i in range(len(countries)):\n",
    "#     print(countries[i] + ' ' + ' '.join(list(map(lambda e : str(conf_matrix.get((countries[i], e), 0)).rjust(3), countries))))\n",
    "\n",
    "\n",
    "results = {}\n",
    "for country in countries:\n",
    "    tp = conf_matrix.get((country, country), 0)\n",
    "    fn = sum(list(map(lambda item : conf_matrix.get((item, country), 0) if country != item else 0, countries)))\n",
    "    fp = sum(list(map(lambda item : conf_matrix.get((country, item), 0) if country != item else 0, countries)))\n",
    "    tn = sum([conf_matrix.get(entry, 0) for entry in product(countries, countries) if (entry[0] != country and entry[1] != country)])\n",
    "\n",
    "    beta = 1.0\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    sensitivity = 0 if tp == 0 and fn == 0 else tp / (tp + fn)\n",
    "    specificity = 0 if fp == 0 and tn == 0 else tn / (fp + tn)\n",
    "    precision = 0 if tp == 0 and fp == 0 else tp / (tp + fp)\n",
    "    recall = sensitivity\n",
    "    f_score = 'Precision and recall are 0, can\\'t calculate' if precision == 0 and recall == 0 else ( (beta**2 + 1) * precision * recall) / (beta**2 * precision + recall)\n",
    "    auc = (sensitivity + specificity) / 2\n",
    "    youden = sensitivity - (1 - specificity)\n",
    "    p_plus = 'Specificity is 1, can\\'t calculate' if specificity == 1 else sensitivity / (1 - specificity)\n",
    "    p_minus = (1 - sensitivity) / specificity\n",
    "    dp = 'Specificity is 1, can\\'t calculate' if specificity == 1 else (np.sqrt(3) / np.pi) * (np.log(sensitivity/(1 - sensitivity) + np.log(specificity/(1 - specificity))))\n",
    "\n",
    "    result = {}\n",
    "    result[\"tp\"] = tp\n",
    "    result[\"tn\"] = tn\n",
    "    result[\"fp\"] = fp\n",
    "    result[\"fn\"] = fn\n",
    "    result[\"accuracy\"] = accuracy\n",
    "    result[\"sensitivity\"] = sensitivity\n",
    "    result[\"specificity\"] = specificity\n",
    "    result[\"precision\"] = precision\n",
    "    result[\"recall\"] = recall\n",
    "    result[\"f-score\"] = f_score\n",
    "    result[\"AUC\"] = auc\n",
    "    result[\"Youden\"] = youden\n",
    "    result[\"p+\"] = p_plus\n",
    "    result[\"p-\"] = p_minus\n",
    "    result[\"DP\"] = dp\n",
    "\n",
    "    # for k, v in result.items():\n",
    "    #     print(f'{k}: {\"{:.2f}\".format(v)}')\n",
    "\n",
    "    results[country] = result\n",
    "\n",
    "pro = 1\n",
    "for k, v in results.items():\n",
    "    print(f'{k}: {v[\"accuracy\"]}')\n",
    "    pro *= v['accuracy'] if v['accuracy'] > 0 else 1\n",
    "print(pro)\n",
    "\n",
    "print(classification_report(truth, predictions, zero_division=0))\n",
    "\n",
    "print(accuracy_score(truth, predictions, normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b6b0bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 3 4 2 1\n",
      "0.4\n",
      "B 0 0 3 4\n",
      "0.5714285714285714\n",
      "C 1 2 1 3\n",
      "0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.60      0.43      0.50         7\n",
      "           B       0.00      0.00      0.00         0\n",
      "           C       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.37      0.25      0.30        10\n",
      "weighted avg       0.57      0.40      0.47        10\n",
      "\n",
      "0.5142857142857142\n"
     ]
    }
   ],
   "source": [
    "classes = ['A', 'B', 'C']\n",
    "truth = ['C', 'A', 'A', 'A', 'A', 'A', 'C', 'C', 'A', 'A']\n",
    "predictions = ['A', 'C', 'A', 'B', 'A', 'B', 'C', 'A', 'B', 'A']\n",
    "\n",
    "conf_matrix = {}\n",
    "for index in range(len(predictions)):\n",
    "    pred = predictions[index]\n",
    "    act = truth[index]\n",
    "    score = conf_matrix.get((pred, act), 0)\n",
    "    conf_matrix[(pred, act)] = score + 1\n",
    "\n",
    "accs = []\n",
    "for country in classes:\n",
    "    tp = conf_matrix.get((country, country), 0)\n",
    "    fn = sum(list(map(lambda item : conf_matrix.get((item, country), 0) if country != item else 0, classes)))\n",
    "    fp = sum(list(map(lambda item : conf_matrix.get((country, item), 0) if country != item else 0, classes)))\n",
    "    tn = sum(list(map(lambda item : conf_matrix.get((item[0], item[1]), 0) if item[0] != country and item[1] != country else 0, zip(classes, classes))))\n",
    "    print(country, tp, fn, fp, tn)\n",
    "\n",
    "    acc = 0 if tp + tn + fn + fp == 0 else (tp + tn) / (tp + tn + fn + fp)\n",
    "    print(acc)\n",
    "    accs.append(acc)\n",
    "\n",
    "print(classification_report(truth, predictions, zero_division=0))\n",
    "print(sum(accs) / len(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ec23dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GB': {'tp': 14, 'tn': 187, 'fp': 80, 'fn': 100, 'accuracy': 0.5275590551181102, 'sensitivity': 0.12280701754385964, 'specificity': 0.700374531835206, 'precision': 0.14893617021276595, 'recall': 0.12280701754385964, 'f-score': 0.1346153846153846, 'AUC': 0.41159077468953287, 'Youden': -0.17681845062093432, 'p+': 0.4098684210526316, 'p-': 1.2524627075710668, 'DP': -0.006052519918436563}, 'PH': {'tp': 12, 'tn': 189, 'fp': 69, 'fn': 99, 'accuracy': 0.5447154471544715, 'sensitivity': 0.10810810810810811, 'specificity': 0.7325581395348837, 'precision': 0.14814814814814814, 'recall': 0.10810810810810811, 'f-score': 0.125, 'AUC': 0.4203331238214959, 'Youden': -0.1593337523570082, 'p+': 0.4042303172737955, 'p-': 1.2175032175032174, 'DP': 0.06682202512422776}, 'NL': {'tp': 6, 'tn': 195, 'fp': 91, 'fn': 102, 'accuracy': 0.5101522842639594, 'sensitivity': 0.05555555555555555, 'specificity': 0.6818181818181818, 'precision': 0.061855670103092786, 'recall': 0.05555555555555555, 'f-score': 0.058536585365853655, 'AUC': 0.3686868686868687, 'Youden': -0.26262626262626265, 'p+': 0.17460317460317457, 'p-': 1.3851851851851853, 'DP': -0.10876425097663475}, 'PL': {'tp': 9, 'tn': 192, 'fp': 81, 'fn': 99, 'accuracy': 0.5275590551181102, 'sensitivity': 0.08333333333333333, 'specificity': 0.7032967032967034, 'precision': 0.1, 'recall': 0.08333333333333333, 'f-score': 0.0909090909090909, 'AUC': 0.39331501831501836, 'Youden': -0.21336996336996333, 'p+': 0.2808641975308642, 'p-': 1.3033854166666665, 'DP': -0.02598879250025294}, 'DE': {'tp': 14, 'tn': 187, 'fp': 97, 'fn': 93, 'accuracy': 0.5140664961636828, 'sensitivity': 0.1308411214953271, 'specificity': 0.6584507042253521, 'precision': 0.12612612612612611, 'recall': 0.1308411214953271, 'f-score': 0.12844036697247707, 'AUC': 0.3946459128603396, 'Youden': -0.2107081742793208, 'p+': 0.3830812216976587, 'p-': 1.3200059973012144, 'DP': -0.11826656541830176}, 'RU': {'tp': 6, 'tn': 195, 'fp': 74, 'fn': 101, 'accuracy': 0.5345744680851063, 'sensitivity': 0.056074766355140186, 'specificity': 0.724907063197026, 'precision': 0.075, 'recall': 0.056074766355140186, 'f-score': 0.06417112299465241, 'AUC': 0.3904909147760831, 'Youden': -0.21901817044783378, 'p+': 0.20383935337206366, 'p-': 1.3021327582075246, 'DP': 0.015407573167878294}, 'HU': {'tp': 8, 'tn': 193, 'fp': 98, 'fn': 99, 'accuracy': 0.5050251256281407, 'sensitivity': 0.07476635514018691, 'specificity': 0.6632302405498282, 'precision': 0.07547169811320754, 'recall': 0.07476635514018691, 'f-score': 0.07511737089201877, 'AUC': 0.36899829784500754, 'Youden': -0.2620034043099849, 'p+': 0.22201029944688153, 'p-': 1.395041402353397, 'DP': -0.15237180683635723}, 'IT': {'tp': 9, 'tn': 192, 'fp': 65, 'fn': 97, 'accuracy': 0.5537190082644629, 'sensitivity': 0.08490566037735849, 'specificity': 0.7470817120622568, 'precision': 0.12162162162162163, 'recall': 0.08490566037735849, 'f-score': 0.09999999999999999, 'AUC': 0.41599368621980765, 'Youden': -0.1680126275603847, 'p+': 0.33570391872278665, 'p-': 1.2248919025157232, 'DP': 0.08932998751069751}, 'FI': {'tp': 10, 'tn': 191, 'fp': 103, 'fn': 94, 'accuracy': 0.5050251256281407, 'sensitivity': 0.09615384615384616, 'specificity': 0.6496598639455783, 'precision': 0.08849557522123894, 'recall': 0.09615384615384616, 'f-score': 0.09216589861751152, 'AUC': 0.3729068550497122, 'Youden': -0.25418628990057557, 'p+': 0.27445855115758033, 'p-': 1.391260571888844, 'DP': -0.17811459670075303}, 'SA': {'tp': 11, 'tn': 190, 'fp': 94, 'fn': 87, 'accuracy': 0.5261780104712042, 'sensitivity': 0.11224489795918367, 'specificity': 0.6690140845070423, 'precision': 0.10476190476190476, 'recall': 0.11224489795918367, 'f-score': 0.10837438423645321, 'AUC': 0.39062949123311297, 'Youden': -0.21874101753377406, 'p+': 0.3391228831958315, 'p-': 1.3269602577873254, 'DP': -0.10261857829046586}, 'CZ': {'tp': 9, 'tn': 192, 'fp': 71, 'fn': 89, 'accuracy': 0.556786703601108, 'sensitivity': 0.09183673469387756, 'specificity': 0.7300380228136882, 'precision': 0.1125, 'recall': 0.09183673469387756, 'f-score': 0.10112359550561797, 'AUC': 0.4109373787537829, 'Youden': -0.17812524249243422, 'p+': 0.34018396090830705, 'p-': 1.2439944727891157, 'DP': 0.05050812918972068}, 'FR': {'tp': 11, 'tn': 190, 'fp': 100, 'fn': 84, 'accuracy': 0.522077922077922, 'sensitivity': 0.11578947368421053, 'specificity': 0.6551724137931034, 'precision': 0.0990990990990991, 'recall': 0.11578947368421053, 'f-score': 0.10679611650485436, 'AUC': 0.385480943738657, 'Youden': -0.22903811252268605, 'p+': 0.3357894736842105, 'p-': 1.3495844875346261, 'DP': -0.14209227964528182}, 'CA': {'tp': 13, 'tn': 188, 'fp': 92, 'fn': 81, 'accuracy': 0.5374331550802139, 'sensitivity': 0.13829787234042554, 'specificity': 0.6714285714285714, 'precision': 0.12380952380952381, 'recall': 0.13829787234042554, 'f-score': 0.13065326633165827, 'AUC': 0.40486322188449847, 'Youden': -0.1902735562310031, 'p+': 0.4209065679925994, 'p-': 1.2833861475780897, 'DP': -0.07352696557513276}, 'AU': {'tp': 22, 'tn': 179, 'fp': 87, 'fn': 70, 'accuracy': 0.5614525139664804, 'sensitivity': 0.2391304347826087, 'specificity': 0.6729323308270677, 'precision': 0.2018348623853211, 'recall': 0.2391304347826087, 'f-score': 0.21890547263681595, 'AUC': 0.45603138280483824, 'Youden': -0.08793723439032358, 'p+': 0.7311344327836083, 'p-': 1.130677677920816, 'DP': 0.019373003150488517}, 'SE': {'tp': 9, 'tn': 192, 'fp': 99, 'fn': 80, 'accuracy': 0.5289473684210526, 'sensitivity': 0.10112359550561797, 'specificity': 0.6597938144329897, 'precision': 0.08333333333333333, 'recall': 0.10112359550561797, 'f-score': 0.09137055837563451, 'AUC': 0.38045870496930384, 'Youden': -0.23908259006139235, 'p+': 0.2972420837589377, 'p-': 1.3623595505617978, 'DP': -0.14061802229639736}, 'US': {'tp': 12, 'tn': 189, 'fp': 83, 'fn': 76, 'accuracy': 0.5583333333333333, 'sensitivity': 0.13636363636363635, 'specificity': 0.6948529411764706, 'precision': 0.12631578947368421, 'recall': 0.13636363636363635, 'f-score': 0.13114754098360656, 'AUC': 0.41560828877005346, 'Youden': -0.16878342245989308, 'p+': 0.44687842278203715, 'p-': 1.242905242905243, 'DP': -0.010687812379439889}, 'BR': {'tp': 15, 'tn': 186, 'fp': 115, 'fn': 73, 'accuracy': 0.5167095115681234, 'sensitivity': 0.17045454545454544, 'specificity': 0.6179401993355482, 'precision': 0.11538461538461539, 'recall': 0.17045454545454544, 'f-score': 0.13761467889908258, 'AUC': 0.3941973723950468, 'Youden': -0.21160525520990633, 'p+': 0.44614624505928857, 'p-': 1.3424364613880742, 'DP': -0.20754730806660585}, 'KR': {'tp': 11, 'tn': 190, 'fp': 100, 'fn': 75, 'accuracy': 0.5345744680851063, 'sensitivity': 0.12790697674418605, 'specificity': 0.6551724137931034, 'precision': 0.0990990990990991, 'recall': 0.12790697674418605, 'f-score': 0.1116751269035533, 'AUC': 0.39153969526864474, 'Youden': -0.21692060946271052, 'p+': 0.3709302325581395, 'p-': 1.3310893512851898, 'DP': -0.13099398525545702}}\n",
      "0.531382725112707\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "print(sum([v['accuracy'] for k, v in results.items() if isinstance(v['accuracy'], float)]) / len(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "classes = ['A', 'B', 'C']\n",
    "\n",
    "truth = ['C', 'A', 'A', 'A', 'A', 'A', 'C', 'C', 'A', 'A']\n",
    "pred = ['A', 'C', 'A', 'B', 'A', 'B', 'C', 'A', 'B', 'A']\n",
    "\n",
    "# print(truth)\n",
    "# print(pred)\n",
    "\n",
    "tp = 4\n",
    "fn = 6\n",
    "fp = 6\n",
    "tn = 14\n",
    "\n",
    "beta = 1.0\n",
    "accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (fp + tn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = sensitivity\n",
    "f_score = ( (beta**2 + 1) * precision * recall) / (beta**2 * precision + recall)\n",
    "auc = (sensitivity + specificity) / 2\n",
    "youden = sensitivity - (1 - specificity)\n",
    "p_plus = sensitivity / (1 - specificity)\n",
    "p_minus = (1 - sensitivity) / specificity\n",
    "dp = (np.sqrt(3) / np.pi) * (np.log(sensitivity/(1 - sensitivity) + np.log(specificity/(1 - specificity))))\n",
    "\n",
    "result = {}\n",
    "result[\"tp\"] = tp\n",
    "result[\"tn\"] = tn\n",
    "result[\"fp\"] = fp\n",
    "result[\"fn\"] = fn\n",
    "result[\"accuracy\"] = accuracy\n",
    "result[\"sensitivity\"] = sensitivity\n",
    "result[\"specificity\"] = specificity\n",
    "result[\"precision\"] = precision\n",
    "result[\"recall\"] = recall\n",
    "result[\"f-score\"] = f_score\n",
    "result[\"AUC\"] = auc\n",
    "result[\"Youden\"] = youden\n",
    "result[\"p+\"] = p_plus\n",
    "result[\"p-\"] = p_minus\n",
    "result[\"DP\"] = dp\n",
    "\n",
    "for k, v in result.items():\n",
    "    print(f'{k}: {\"{:.2f}\".format(v)}')\n",
    "\n",
    "print(accuracy_score(truth, pred, normalize=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "cls_type, model = random.choice(list(models.items()))\n",
    "# model = models['SVC']\n",
    "\n",
    "sample = test.sample(1)\n",
    "sample_predict = sample.drop(columns=['countrycode', 'timestamp', 'recognized', 'key_id', 'drawing', 'word']).to_numpy()\n",
    "\n",
    "if pca_on:\n",
    "    sample_predict = scaler.transform(sample_predict)\n",
    "    sample_predict = pca.transform(sample_predict)\n",
    "\n",
    "prediction = model.predict(sample_predict)\n",
    "display(IPImage(render_single(sample['drawing'].iloc[0])))\n",
    "print(f\"Using {cls_type} classifier\")\n",
    "print(f\"{prediction[0]}(predicted) == {sample['word'].iloc[0]}(actual) ? {sample['word'].iloc[0] == prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type, model in models.items():\n",
    "    test2 = test.drop(columns=['countrycode', 'timestamp', 'recognized', 'key_id', 'drawing', 'word']).to_numpy()\n",
    "    if pca_on:\n",
    "        test2 = scaler.transform(test2)\n",
    "        test2 = pca.transform(test2)\n",
    "    prediction = model.predict(test2)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc_score = accuracy_score(test['word'].values.tolist(), prediction)\n",
    "    print(f\"{model_type} classifier, accuracy: {acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae70ea7",
   "metadata": {},
   "source": [
    "LinearSVC classifier, accuracy: 0.9208\n",
    "\n",
    "NuSVC classifier, accuracy: 0.9756\n",
    "\n",
    "SVC classifier, accuracy: 0.9696\n",
    "\n",
    "LinearDiscriminantAnalysis classifier, accuracy: 0.902\n",
    "\n",
    "QuadraticDiscriminantAnalysis classifier, accuracy: 0.9332\n",
    "\n",
    "MLPClassifier classifier, accuracy: 0.9708\n",
    "\n",
    "KernelRidge classifier, accuracy: 0.9036"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
