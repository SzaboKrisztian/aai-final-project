{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import load_run\n",
    "\n",
    "clust = OPTICS(min_samples=50, xi=0.05, min_cluster_size=0.05)\n",
    "\n",
    "run = load_run('1638012544')\n",
    "df = run['data']\n",
    "\n",
    "# Run the fit\n",
    "df2 = df.drop(columns=['countrycode', 'timestamp', 'recognized', 'key_id', 'drawing', 'word'])\n",
    "print(\"DataFrame creation done\")\n",
    "comp_or_var = .85\n",
    "da_pca = PCA(comp_or_var)\n",
    "da_scaler = StandardScaler()\n",
    "df2 = da_pca.fit_transform(df2)\n",
    "print(f\"PCA fit+transform done. Keeping {f'{da_pca.n_components_} features' if comp_or_var < 1 else f'{da_pca.explained_variance_ * 100}% variance'}\")\n",
    "df2 = da_scaler.fit_transform(df2)\n",
    "print(\"Scaler fit+transform done\")\n",
    "clust.fit(df2)\n",
    "print(\"OPTICS clustering done\")\n",
    "\n",
    "labels_050 = cluster_optics_dbscan(\n",
    "    reachability=clust.reachability_,\n",
    "    core_distances=clust.core_distances_,\n",
    "    ordering=clust.ordering_,\n",
    "    eps=0.5,\n",
    ")\n",
    "print(\"DBSCAN (0.5) clustering done\")\n",
    "labels_200 = cluster_optics_dbscan(\n",
    "    reachability=clust.reachability_,\n",
    "    core_distances=clust.core_distances_,\n",
    "    ordering=clust.ordering_,\n",
    "    eps=2,\n",
    ")\n",
    "print(\"DBSCAN (2) clustering done\")\n",
    "\n",
    "space = np.arange(len(df2))\n",
    "reachability = clust.reachability_[clust.ordering_]\n",
    "labels = clust.labels_[clust.ordering_]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "G = gridspec.GridSpec(2, 3)\n",
    "ax1 = plt.subplot(G[0, :])\n",
    "ax2 = plt.subplot(G[1, 0])\n",
    "ax3 = plt.subplot(G[1, 1])\n",
    "ax4 = plt.subplot(G[1, 2])\n",
    "\n",
    "# Reachability plot\n",
    "colors = [\"g.\", \"r.\", \"b.\", \"y.\", \"c.\"]\n",
    "for klass, color in zip(range(0, 5), colors):\n",
    "    Xk = space[labels == klass]\n",
    "    Rk = reachability[labels == klass]\n",
    "    ax1.plot(Xk, Rk, color, alpha=0.3)\n",
    "ax1.plot(space[labels == -1], reachability[labels == -1], \"k.\", alpha=0.3)\n",
    "ax1.plot(space, np.full_like(space, 2.0, dtype=float), \"k-\", alpha=0.5)\n",
    "ax1.plot(space, np.full_like(space, 0.5, dtype=float), \"k-.\", alpha=0.5)\n",
    "ax1.set_ylabel(\"Reachability (epsilon distance)\")\n",
    "ax1.set_title(\"Reachability Plot\")\n",
    "\n",
    "# OPTICS\n",
    "colors = [\"g.\", \"r.\", \"b.\", \"y.\", \"c.\"]\n",
    "for klass, color in zip(range(0, 5), colors):\n",
    "    Xk = df2[clust.labels_ == klass]\n",
    "    ax2.plot(Xk[:, 0], Xk[:, 1], color, alpha=0.3)\n",
    "ax2.plot(df2[clust.labels_ == -1, 0], df2[clust.labels_ == -1, 1], \"k+\", alpha=0.1)\n",
    "ax2.set_title(\"Automatic Clustering\\nOPTICS\")\n",
    "\n",
    "# DBSCAN at 0.5\n",
    "colors = [\"g\", \"greenyellow\", \"olive\", \"r\", \"b\", \"c\"]\n",
    "for klass, color in zip(range(0, 6), colors):\n",
    "    Xk = df2[labels_050 == klass]\n",
    "    ax3.plot(Xk[:, 0], Xk[:, 1], color, alpha=0.3, marker=\".\")\n",
    "ax3.plot(df2[labels_050 == -1, 0], df2[labels_050 == -1, 1], \"k+\", alpha=0.1)\n",
    "ax3.set_title(\"Clustering at 0.5 epsilon cut\\nDBSCAN\")\n",
    "\n",
    "# DBSCAN at 2.\n",
    "colors = [\"g.\", \"m.\", \"y.\", \"c.\"]\n",
    "for klass, color in zip(range(0, 4), colors):\n",
    "    Xk = df2[labels_200 == klass]\n",
    "    ax4.plot(Xk[:, 0], Xk[:, 1], color, alpha=0.3)\n",
    "ax4.plot(df2[labels_200 == -1, 0], df2[labels_200 == -1, 1], \"k+\", alpha=0.1)\n",
    "ax4.set_title(\"Clustering at 2.0 epsilon cut\\nDBSCAN\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from utils import extract_first_entries, generate_pixel_columns\n",
    "\n",
    "file = './dataset/sandwich.ndjson'\n",
    "df = extract_first_entries(file, recognized=True)\n",
    "print('Done loading')\n",
    "df = generate_pixel_columns(df, 32, 1, True)\n",
    "print('Done generating pixel columns')\n",
    "x = df.filter(regex=('pixel.+'))\n",
    "y = df['countrycode']\n",
    "\n",
    "# wcss = []\n",
    "# for i in range(1,11):\n",
    "#    print(f'Fitting model {i}/10...')\n",
    "#    model = KMeans(n_clusters = i, init = \"k-means++\")\n",
    "#    model.fit(x)\n",
    "#    wcss.append(model.inertia_)\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.plot(range(1,11), wcss)\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('WCSS')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AffinityPropagation, AgglomerativeClustering, SpectralClustering, Birch, MeanShift, OPTICS, DBSCAN, estimate_bandwidth\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from IPython.display import display, Image as ipimg\n",
    "from utils import render_multiple\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "num_clusters = 2\n",
    "pca = PCA(2)\n",
    "data = pca.fit_transform(x)\n",
    "print('Done transforming data')\n",
    "# con = kneighbors_graph(data, n_neighbors=10, include_self=False)\n",
    "\n",
    "# outlier_det = IsolationForest(random_state=42)\n",
    "# outliers = outlier_det.fit_predict(data)\n",
    "\n",
    "# bandwidth = estimate_bandwidth(x, quantile=.1)\n",
    "# print('Done with bandwidth estimation')\n",
    "\n",
    "clsts = {\n",
    "    'KMeans': KMeans(n_clusters = num_clusters, init = \"k-means++\"),\n",
    "    # 'AgglomerativeAverage': AgglomerativeClustering(\n",
    "    #     linkage='average',\n",
    "    #     affinity=\"cityblock\",\n",
    "    #     n_clusters=num_clusters,\n",
    "    #     connectivity=con\n",
    "    # ),\n",
    "    # 'AgglomerativeWard': AgglomerativeClustering(\n",
    "    #     linkage='ward',\n",
    "    #     n_clusters=num_clusters,\n",
    "    #     connectivity=con\n",
    "    # ),\n",
    "    # 'SpectralClustering': SpectralClustering(\n",
    "    #     n_clusters=num_clusters,\n",
    "    #     eigen_solver=\"arpack\",\n",
    "    #     affinity=\"nearest_neighbors\",\n",
    "    # ),\n",
    "    'Birch': Birch(n_clusters=num_clusters),\n",
    "    'Gaussian': GaussianMixture(\n",
    "        n_components=num_clusters, covariance_type=\"full\"\n",
    "    ),\n",
    "    # 'MeanShift': MeanShift(bandwidth=bandwidth, bin_seeding=True),\n",
    "    # 'OPTICS': OPTICS(min_cluster_size=.1,xi=.05,min_samples=20),\n",
    "    # 'DBSCAN': DBSCAN(eps=.3)\n",
    "}\n",
    "\n",
    "df3 = pd.DataFrame(data)\n",
    "df3['drawing'] = df['drawing']\n",
    "df3['countrycode'] = y\n",
    "# df3['outlier'] = np.array(map(lambda n: 1 if n < 0 else 0, outliers))\n",
    "# df3 = df3[df3['outlier'] == 0]\n",
    "for typ, clst in clsts.items():\n",
    "    pixels = df3.filter(regex='[01]')\n",
    "    model = clst.fit_predict(pixels)\n",
    "    print(f\"Done fitting model {typ}\")\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    clusters = np.unique(model)\n",
    "\n",
    "    for cluster in clusters:\n",
    "        drawings = df3[model == cluster]['drawing']\n",
    "        display(ipimg(render_multiple(drawings if len(drawings) < 2000 else drawings.sample(2000))))\n",
    "        print(f'Entries: {len(drawings)}')\n",
    "        plt.scatter(df3[model == cluster][0] , df3[model == cluster][1] , label = cluster)\n",
    "    plt.legend()\n",
    "\n",
    "    # data2 = pd.DataFrame(data)\n",
    "    # data2['countrycode'] = y\n",
    "    # data2['outlier'] = np.array(map(lambda n: 1 if n < 0 else 0, outliers))\n",
    "    # country = df3[df3['countrycode'].isin(['RO', 'BR'])]\n",
    "    # plt.scatter(country[0], country[1], marker='.', color='k')\n",
    "    # plt.scatter(data2[data2['outlier'] == 1][0], data2[data2['outlier'] == 1][1], c='red')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./dataset/ambulance.ndjson...\n",
      "Created directory \"./clustering/ambulance\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/ambulance/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/bed.ndjson...\n",
      "Created directory \"./clustering/bed\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/bed/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/bench.ndjson...\n",
      "Created directory \"./clustering/bench\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/bench/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/bread.ndjson...\n",
      "Created directory \"./clustering/bread\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/bread/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/castle.ndjson...\n",
      "Created directory \"./clustering/castle\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/castle/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/cell phone.ndjson...\n",
      "Created directory \"./clustering/cell-phone\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/cell-phone/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/chair.ndjson...\n",
      "Created directory \"./clustering/chair\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/chair/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/church.ndjson...\n",
      "Created directory \"./clustering/church\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/church/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/coffee cup.ndjson...\n",
      "Created directory \"./clustering/coffee-cup\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/coffee-cup/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/crown.ndjson...\n",
      "Created directory \"./clustering/crown\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/crown/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/cup.ndjson...\n",
      "Created directory \"./clustering/cup\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/cup/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/diamond.ndjson...\n",
      "Created directory \"./clustering/diamond\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/diamond/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/dishwasher.ndjson...\n",
      "Created directory \"./clustering/dishwasher\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/dishwasher/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/dresser.ndjson...\n",
      "Created directory \"./clustering/dresser\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/dresser/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/eye.ndjson...\n",
      "Created directory \"./clustering/eye\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/eye/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/face.ndjson...\n",
      "Created directory \"./clustering/face\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/face/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/fan.ndjson...\n",
      "Created directory \"./clustering/fan\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/fan/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/fire hydrant.ndjson...\n",
      "Created directory \"./clustering/fire-hydrant\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/fire-hydrant/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/fish.ndjson...\n",
      "Created directory \"./clustering/fish\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/fish/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/hammer.ndjson...\n",
      "Created directory \"./clustering/hammer\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/hammer/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/hat.ndjson...\n",
      "Created directory \"./clustering/hat\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/hat/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/helicopter.ndjson...\n",
      "Created directory \"./clustering/helicopter\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/helicopter/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/ice cream.ndjson...\n",
      "Created directory \"./clustering/ice-cream\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/ice-cream/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/lantern.ndjson...\n",
      "Created directory \"./clustering/lantern\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/lantern/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/passport.ndjson...\n",
      "Created directory \"./clustering/passport\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/passport/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/pickup truck.ndjson...\n",
      "Created directory \"./clustering/pickup-truck\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/pickup-truck/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/pillow.ndjson...\n",
      "Created directory \"./clustering/pillow\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/pillow/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/power outlet.ndjson...\n",
      "Created directory \"./clustering/power-outlet\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/power-outlet/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/sailboat.ndjson...\n",
      "Created directory \"./clustering/sailboat\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/sailboat/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/sandwich.ndjson...\n",
      "Created directory \"./clustering/sandwich\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/sandwich/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/snowman.ndjson...\n",
      "Created directory \"./clustering/snowman\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/snowman/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/strawberry.ndjson...\n",
      "Created directory \"./clustering/strawberry\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/strawberry/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/suitcase.ndjson...\n",
      "Created directory \"./clustering/suitcase\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/suitcase/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/table.ndjson...\n",
      "Created directory \"./clustering/table\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/table/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/telephone.ndjson...\n",
      "Created directory \"./clustering/telephone\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/telephone/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/traffic light.ndjson...\n",
      "Created directory \"./clustering/traffic-light\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/traffic-light/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/watermelon.ndjson...\n",
      "Created directory \"./clustering/watermelon\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/watermelon/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n",
      "Processing ./dataset/wine glass.ndjson...\n",
      "Created directory \"./clustering/wine-glass\n",
      "Done loading\n",
      "Done generating pixel columns\n",
      "Done transforming data\n",
      "Done with outlier detection\n",
      "Created directory \"./clustering/wine-glass/KMeans/\n",
      "Done fitting model KMeans\n",
      "Done saving images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, AffinityPropagation, AgglomerativeClustering, SpectralClustering, Birch, MeanShift, estimate_bandwidth\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from IPython.display import display, Image as ipimg\n",
    "from PIL import Image as pilimg\n",
    "from utils import render_multiple\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from utils import extract_first_entries, generate_pixel_columns\n",
    "import os, io\n",
    "\n",
    "files = {\n",
    "    './dataset/ambulance.ndjson' :2,\n",
    "    './dataset/bed.ndjson' :2,\n",
    "    './dataset/bench.ndjson' :2,\n",
    "    './dataset/bread.ndjson' :2,\n",
    "    './dataset/castle.ndjson' :3,\n",
    "    './dataset/cell phone.ndjson' :2,\n",
    "    './dataset/chair.ndjson' :3,\n",
    "    './dataset/church.ndjson' :2,\n",
    "    './dataset/coffee cup.ndjson' :3,\n",
    "    './dataset/crown.ndjson' :2,\n",
    "    './dataset/cup.ndjson' :2,\n",
    "    './dataset/diamond.ndjson' :2,\n",
    "    './dataset/dishwasher.ndjson' :2,\n",
    "    './dataset/dresser.ndjson' :2,\n",
    "    './dataset/eye.ndjson' :2,\n",
    "    './dataset/face.ndjson' :2,\n",
    "    './dataset/fan.ndjson' :2,\n",
    "    './dataset/fire hydrant.ndjson' :2,\n",
    "    './dataset/fish.ndjson' :2,\n",
    "    './dataset/hammer.ndjson' :2,\n",
    "    './dataset/hat.ndjson' :3,\n",
    "    './dataset/helicopter.ndjson' :3,\n",
    "    './dataset/ice cream.ndjson' :2,\n",
    "    './dataset/lantern.ndjson' :2,\n",
    "    './dataset/passport.ndjson' :2,\n",
    "    './dataset/pickup truck.ndjson' :2,\n",
    "    './dataset/pillow.ndjson' :2,\n",
    "    './dataset/power outlet.ndjson' :2,\n",
    "    './dataset/sailboat.ndjson' :2,\n",
    "    './dataset/sandwich.ndjson' :3,\n",
    "    './dataset/snowman.ndjson' :2,\n",
    "    './dataset/strawberry.ndjson' :2,\n",
    "    './dataset/suitcase.ndjson' :2,\n",
    "    './dataset/table.ndjson' :2,\n",
    "    './dataset/telephone.ndjson' :2,\n",
    "    './dataset/traffic light.ndjson' :2,\n",
    "    './dataset/watermelon.ndjson' :2,\n",
    "    './dataset/wine glass.ndjson' :2,\n",
    "}\n",
    "if not os.path.exists('./clustering'):\n",
    "    os.makedirs('./clustering')\n",
    "\n",
    "for file, num_clusters in files.items():\n",
    "    print(f'Processing {file}...')\n",
    "    slash_idx = file.rindex('/')\n",
    "    ext_idx = file.rindex('.ndjson')\n",
    "    dir_name = './clustering/' + file[slash_idx + 1:ext_idx].replace(' ', '-')\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "        print(f'Created directory \"{dir_name}')\n",
    "    else:\n",
    "        print(f'Directory \"{dir_name}\" already exists.')\n",
    "\n",
    "    df = extract_first_entries(file, recognized=True)\n",
    "    print('Done loading')\n",
    "    df = generate_pixel_columns(df, 32, 1, True)\n",
    "    print('Done generating pixel columns')\n",
    "    x = df.filter(regex=('pixel.+'))\n",
    "    y = df['countrycode']\n",
    "\n",
    "    pca = PCA(2)\n",
    "    data = pca.fit_transform(x)\n",
    "    print('Done transforming data')\n",
    "\n",
    "    outlier_det = IsolationForest(random_state=42)\n",
    "    outliers = outlier_det.fit_predict(data)\n",
    "    print('Done with outlier detection')\n",
    "\n",
    "    # bandwidth = estimate_bandwidth(x, quantile=.1)\n",
    "\n",
    "    clsts = {\n",
    "        'KMeans': KMeans(n_clusters = num_clusters, init = \"k-means++\"),\n",
    "        # 'Birch': Birch(n_clusters=num_clusters),\n",
    "        # 'Gaussian': GaussianMixture(\n",
    "        #     n_components=num_clusters, covariance_type=\"full\"\n",
    "        # ),\n",
    "        # 'MeanShift': MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    }\n",
    "\n",
    "    df3 = pd.DataFrame(data)\n",
    "    df3['outlier'] = np.array(map(lambda n: 1 if n < 0 else 0, outliers))\n",
    "    df3['drawing'] = df['drawing']\n",
    "    df3['countrycode'] = y\n",
    "    df3 = df3[df3['outlier'] == 0]\n",
    "\n",
    "    for typ, clst in clsts.items():\n",
    "        inner_dir = f'{dir_name}/{typ}/'\n",
    "        if not os.path.exists(inner_dir):\n",
    "            os.makedirs(inner_dir)\n",
    "            print(f'Created directory \"{inner_dir}')\n",
    "        pixels = df3.filter(regex='[01]')\n",
    "        model = clst.fit_predict(pixels)\n",
    "        print(f\"Done fitting model {typ}\")\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        clusters = np.unique(model)\n",
    "\n",
    "        for cluster in clusters:\n",
    "            drawings = df3[model == cluster]['drawing']\n",
    "            img = pilimg.open(io.BytesIO(render_multiple(drawings if len(drawings) < 2000 else drawings.sample(2000))))\n",
    "            img.save(inner_dir + 'cluster' + str(cluster) + '.png')\n",
    "            plt.scatter(df3[model == cluster][0] , df3[model == cluster][1] , label = cluster)\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(inner_dir + 'plot.png')\n",
    "        with open(inner_dir + 'stats.txt', 'w', encoding='utf8') as stats_file:\n",
    "            stats_file.write(f'total entries: {len(df3)}\\n')\n",
    "            for cluster in clusters:\n",
    "                stats_file.write(f'cluster{cluster} entries: {len(df3[model == cluster])}\\n')\n",
    "        print('Done saving images.')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import hsv_to_rgb\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "data2 = pd.DataFrame(data)\n",
    "data2['countrycode'] = y\n",
    "counts = data2['countrycode'].value_counts()\n",
    "counts = counts[(counts > 1000)]\n",
    "groups = list(counts.to_dict().keys())\n",
    "data2 = data2[data2['countrycode'].isin(groups)]\n",
    "grouped = data2.groupby('countrycode')\n",
    "\n",
    "colors = {key:hsv_to_rgb([((value+1)/len(groups)), .8, .75]) for value, key in enumerate(groups)}\n",
    "\n",
    "for key, group in grouped:\n",
    "    subgroup = group.sample(5) if len(group)>5 else group\n",
    "    subgroup.plot(ax=ax, kind='scatter', x=0, y=1, label=key, color=[colors[key]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
