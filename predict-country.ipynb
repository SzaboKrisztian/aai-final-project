{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Processing \"car\" (1/1):\n",
      "Extracted 27000 entries from category car\n",
      "Retained 27 countries\n",
      "Train: 24300 entries, test: 2700 entries.\n",
      "Done generating features and target\n",
      "PCA & standardization done. Keeping 504 features\n",
      "Done training model in 731.36s\n",
      "Done saving model, pca, and scaler to disk\n",
      "Category \"car\"\n",
      "\n",
      "{'magnification': 1, 'resolution': 32, 'invert_color': True, 'stroke_width_scale': 1}\n",
      "[('KR', 17.346938775510203), ('TW', 12.5), ('JP', 9.174311926605505), ('AE', 8.421052631578947), ('CZ', 8.421052631578947), ('VN', 7.865168539325842), ('DE', 7.8431372549019605), ('PH', 6.862745098039216), ('IN', 6.862745098039216), ('SA', 6.730769230769231), ('BR', 6.5420560747663545), ('TH', 6.25), ('FI', 5.952380952380952), ('NL', 4.901960784313726), ('AU', 4.25531914893617), ('RO', 4.2105263157894735), ('SK', 4.0), ('PL', 3.4090909090909087), ('FR', 3.3707865168539324), ('HU', 3.260869565217391), ('GB', 3.1914893617021276), ('IT', 2.941176470588235), ('ID', 2.857142857142857), ('RU', 2.727272727272727), ('US', 2.6548672566371683), ('CA', 2.5210084033613445), ('SE', 0.0)]\n",
      "\n",
      "Scores greater than 3.70% (random chance):\n",
      "  KR: 17.35%\n",
      "  TW: 12.50%\n",
      "  JP: 9.17%\n",
      "  AE: 8.42%\n",
      "  CZ: 8.42%\n",
      "  VN: 7.87%\n",
      "  DE: 7.84%\n",
      "  PH: 6.86%\n",
      "  IN: 6.86%\n",
      "  SA: 6.73%\n",
      "  BR: 6.54%\n",
      "  TH: 6.25%\n",
      "  FI: 5.95%\n",
      "  NL: 4.90%\n",
      "  AU: 4.26%\n",
      "  RO: 4.21%\n",
      "  SK: 4.00%\n",
      "Overall accuracy: 0.06%\n",
      "\n",
      "Finished processing cateogory in 12m32s\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from itertools import repeat\n",
    "import time, os, joblib\n",
    "import pandas as pd\n",
    "from utils import generate_pixel_columns, extract_best_entries, extract_first_entries, equalize_by\n",
    "\n",
    "categories = ['car']\n",
    "# categories = ['ambulance','bed','bench','bread','castle','cell phone','chair','church','coffee cup','crown','cruise ship','cup','dishwasher','dresser','eye','face',\n",
    "    # 'fan','fire hydrant','fish','hammer','hat','helicopter','ice cream','lantern','passport','pickup truck','pillow','power outlet','sailboat','sandwich','snowman',\n",
    "    # 'star','strawberry','suitcase','table','telephone','traffic light','watermelon','wine glass']\n",
    "\n",
    "image_gen_params = {\n",
    "    'magnification': 1,\n",
    "    'resolution': 32,\n",
    "    'invert_color': True,\n",
    "    'stroke_width_scale': 1\n",
    "}\n",
    "\n",
    "root = './countries'\n",
    "if not os.path.exists(root):\n",
    "    os.makedirs(root)\n",
    "\n",
    "done = 0\n",
    "for category in categories:\n",
    "    t0 = time.time()\n",
    "    print(f'Processing \"{category}\" ({done + 1}/{len(categories)}):')\n",
    "    folder = f'{root}/{category}'\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    df = extract_first_entries(f'./dataset/{category}.ndjson', recognized=True)\n",
    "    df = equalize_by(df, 'countrycode')\n",
    "    print(f\"Extracted {len(df)} entries from category {category}\")\n",
    "    print(f\"Retained {len(df['countrycode'].value_counts())} countries\")\n",
    "    df = generate_pixel_columns(df, **image_gen_params)\n",
    "\n",
    "    train_amt = int(len(df) * .9)\n",
    "\n",
    "    train = df[:train_amt]\n",
    "    test = df[train_amt:]\n",
    "\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "\n",
    "    print(f'Train: {len(train)} entries, test: {len(test)} entries.')\n",
    "\n",
    "    y = train['countrycode'].to_numpy()\n",
    "    X = train.filter(regex='pixel.+').to_numpy()\n",
    "    print(\"Done generating features and target\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    pca = PCA(.85)\n",
    "    X = pca.fit_transform(X)\n",
    "    print(f'PCA & standardization done. Keeping {pca.n_components_} features')\n",
    "\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=tuple(repeat(int(pca.n_components_ * 1.2), 3)), solver='lbfgs', alpha=1e-07)\n",
    "    start = time.time()\n",
    "    model = OneVsRestClassifier(classifier, n_jobs=-1).fit(X, y)\n",
    "    end = time.time()\n",
    "    print(f\"Done training model in {'{:.2f}'.format(end - start)}s\")\n",
    "    joblib.dump(model, folder + '/model')\n",
    "    joblib.dump(pca, folder + '/pca')\n",
    "    joblib.dump(scaler, folder + '/scaler')\n",
    "    print(\"Done saving model, pca, and scaler to disk\")\n",
    "\n",
    "    test2 = test.filter(regex='pixel.+').to_numpy()\n",
    "    test2 = scaler.transform(test2)\n",
    "    test2 = pca.transform(test2)\n",
    "    prediction = model.predict(test2)\n",
    "\n",
    "    countries = list(test['countrycode'].value_counts().keys())\n",
    "    counts = {}\n",
    "    for idx in range(len(test)):\n",
    "        country = test['countrycode'].iloc[idx]\n",
    "        entry_score = counts.get(country, (0, 0))\n",
    "        entry_score = (entry_score[0] + 1 if prediction[idx] == country else entry_score[0], entry_score[1] + 1)\n",
    "        counts[country] = entry_score\n",
    "    scores = {}\n",
    "    for country in countries:\n",
    "        scores[country] = (counts[country][0] / counts[country][1]) * 100\n",
    "\n",
    "    scores = [(k, v) for k, v in scores.items()]\n",
    "    scores.sort(key=lambda e : e[1], reverse=True)\n",
    "    threshold = 100 / len(countries)\n",
    "\n",
    "    out = []\n",
    "\n",
    "    out.append(f'Category \"{category}\"\\n')\n",
    "    out.append(str(image_gen_params))\n",
    "    out.append(str(scores) + '\\n')\n",
    "\n",
    "    out.append(f'Scores greater than {\"{:.2f}\".format(threshold)}% (random chance):')\n",
    "    for entry in scores:\n",
    "        if entry[1] > threshold:\n",
    "            out.append(f'  {entry[0]}: {\"{:.2f}\".format(entry[1])}%')\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc_score = accuracy_score(test['countrycode'].values.tolist(), prediction)\n",
    "    out.append(f\"Overall accuracy: {'{:.2f}'.format(acc_score)}%\\n\")\n",
    "\n",
    "    out = '\\n'.join(out)\n",
    "    with open(folder + '/stats', 'w') as f:\n",
    "        f.write(out)\n",
    "\n",
    "    print(out)\n",
    "\n",
    "    duration = time.time() - t0\n",
    "    print(f\"Finished processing cateogory in {int(duration // 60)}m{int(duration % 60)}s\")\n",
    "    done += 1\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
